\documentclass{bioinfo}
\copyrightyear{2009}
\pubyear{2009}

\usepackage{url}

\newcommand{\cli}{\textsc{CLI}}
\newcommand{\gui}{\textsc{GUI}}
\newcommand{\unix}{Unix}
\newcommand{\prog}[1]{\texttt{nw\_#1}}
\newcommand{\nutils}{Newick Utilities}
\newcommand{\unix}{\textsc{Unix}}

\begin{document}
\firstpage{1}

\title{\unix{} Shell Filters for Newick Trees}
\author[Junier and Zdobnov]{Thomas Junier\,$^{1}$\footnote{to whom correspondence should be addressed}\hspace{1em}and Evgeny Zdobnov}
\address{$^{1}$Department of Genetic and Development Medicine, Faculty of Medicine, University of Geneva, Geneva, Switzerland}

\history{Received on 2009-xx-yy\ldots}


\editor{Associate Editor: John Milton}

\maketitle

\begin{abstract}
\emph{[Abstract is now structered as per Instructions]}
\section{Summary:}
A set of \unix{} shell tools for working with phylogenetic trees, designed for working with large volumes of data and to make automation easy.
\section{Availability:}
C source code and examples are available from \url{http://cegg.unige.ch/newick-utils}.
\section{Contact:}
\href{thomas.junier@unige.ch}{thomas.junier@unige.ch}
\end{abstract}
 
\section{Introduction}

Some applications in phylogeny involve large numbers of trees. Once the trees have been constructed, they must often be processed, involving steps like (re)rooting, extracting branch lengths, computing support values, pruning, extracting subtrees, etc. To avoid human errors, it is desirable that the whole process  be automated. This is typically done in an analysis pipeline, possibly involving many programs.

The ease of automation will depend on the type of interface the programs offer. In general, it is harder to automate a program that requires user interaction than one that doesn't. The ability to work on several trees (rather than a single one) is also a plus.

All main methods for \textit{constructing} trees have command-line implementations (\textit{e.g.}, PhyML (\cite{Guindon2003}), BioNJ (\cite{Gascuel1997}), etc); these lend themselves well to automation. 
The situation is different for tree processing: although there is a large choice of programs for manipulating trees (e.g.
NJplot \cite{Perri√®re1996} or TreeView \cite{Page2002}), most have an interactive, graphical interface, which is hard or impossible to automate.

Automation is also facilitated by good interoperation between the programs involved, when there is more than one. The ability to read data from standard input and write results on standard output is one way of providing this in a \unix{} shell environment. Programs that have these properties are termed \textit{filters}.

Faced with the need to handle large numbers of trees in automated pipelines, and having failed to find any software that met our needs, we designed and wrote a collection of filters that perform a range of frequently used tree operations, require no user interaction, and work with any number of trees of any size. 

\begin{table}[!t]
\processtable{\nutils\label{tab:NU_func}}
{\begin{tabular*}{\columnwidth}{lp{0.7 \columnwidth}}\toprule
Program & Function \\ 
\hline 
\prog{reroot} & reroot trees on outgroup, specified by labels \\
\prog{clade} & extract subtrees defined by labels \\
\prog{distance} & extract branch lengths in various ways (from root, from parent, as matrix, etc.) \\
\prog{labels} & extract labels (leaf, inner nodes, or both) \\
\prog{support} & attribute support values to a known tree based on bootstrap replicates \\
\prog{rename} & rename node labels based on a mapping \\
\prog{order} & order tree nodes (without changing topology) \\
\prog{topology} & extract topological information (by discarding branch length data, etc) \\
\prog{condense} & simplify trees (e.g. whole clades of the same label) \\
\prog{prune} & discard nodes by label \\
 \ldots & [maybe keep only the most interesting] \\
\hline
\end{tabular*}}{}
\end{table}

\section{Results}

The \nutils{} perform the functions listed in table \ref{tab:NU_func}. They have the following common properties:

\begin{itemize}
 \item no user interaction is required
 \item the input format is Newick (see \url{http://evolution.genetics.washington.edu/phylip/newicktree.html})
 \item there is no arbitrary limit on the number or size of the input trees
 \item all the output is text; those programs which output trees output Newick
 \item the data are read from a file or from standard input; results are written to standard output
 \item all options are passed on the command line (no control files)
 \item documentation is available with option \texttt{-h}
\end{itemize}

\section*{Examples}

\emph{[maybe just one longer example, rather than two shoretr ones?]}

\subsection*{Principal Components Analysis of Branch Lengths}

Suppose we are interested in the evolution rates of about one thousand 1:1 orthologs from 7 tetrapod species. We produce the $\sim$ 1,000 maximum-likelihood trees, and we want to submit the branch lengths to \textsc{PCA}. Suppose further that we used three ``fishes'', \textit{Fugu}, \textit{Tetraodon} and \textit{Danio}, as outgroup. Finally, say the trees are in a file named \texttt{vertebrata.txt}. The steps involved are:
\begin{enumerate}
 \item reroot all the trees on the ``fishes'' -- ML trees are unrooted
 \item extract the branch lengths for all tetrapods, from their last common ancestor to the tip
\end{enumerate}
This can be done in the following way (edited to fit page width):

\begin{verbatim}
$ nw_reroot vertebrata.txt Danio Fugu Tetraodon | 
nw_distance -t -m lca - Xenopus Gallus Monodelphis
Bos Canis Mus Homo 
\end{verbatim}

\prog{reroot} reads in all the trees in \texttt{vertebrata.txt} and reroots
them on the clade defined by the ``fishes''. The result is written on standard
output, which is piped into \prog{distance}. For each (now rerooted) tree,
this program finds the last common ancestor of (\texttt{Xenopus} to
\texttt{Homo}), and prints out the length from that node to each of the
tetrapod tips, on one line. The result is a rectangular matrix of 10 columns
and 1000 lines, suitable for \textsc{PCA}.

\subsection*{Bootscanning}

In this technique, we look for recombination breakpoints by finding the nearest neighbor of some reference sequence along a multiple alignment. The alignment is divided into equidistant windows of constant size, and a bootstrapped tree is computed for each window. Then we extract the refrence sequence's nearest neighbor, and the support value of the corresponding clade.

Assuming the trees are in file \verb|win_trees|, extracting the siblings is done like this:
\begin{verbatim}
$ nw_reroot win_trees Out | nw_clade -s - Ref 
\end{verbatim}
where \texttt{Out} is the label of the outgroup, and \texttt{Ref} is the label of the reference sequence. The first step roots the trees on the outgroup (failing which the subtree extraction of the next step will likely fail). The second step extracts the sibling (\texttt{-s}) of the reference. 

The following pipeline extracts the support values:
\begin{verbatim}
$ nw_reroot win_trees Out | nw_clade -c1 - Ref | sed 's/^.*://' | tr -d ';'
\end{verbatim}

\section{Discussion}

\emph{[I'm not sure what to say here\ldots]}

In our opinion, one of the most useful features of Unix shells is the ability
to  ``glue'' arbitrary programs together in pipelines or shell scripts. This
is (partly) because research is sufficiently unpredictable for any specialized
tool to be confronted, sooner or later, with a problem it wasn't designed for.
We found that the ``Unix Philosophy'' (\textit{e.g.} \cite{Gancarz2002})
tenets of i) making every program a filter, ii) making every program do one
thing well, and iii) avoiding captive interfaces work well in practice, and we
designed the Newick Utilities with these guidelines in mind. 

\section*{Acknowlkedgements}
\emph{[Instructions: must cite sources of funding]}

\bibliographystyle{natbib} 
\bibliography{article}


\end{document}
